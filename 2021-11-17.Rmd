##  Running and blood sugar (18.10)


 A diabetic wants to know how aerobic exercise affects his
blood sugar. When his blood sugar reaches 170 (mg/dl), he goes out for
a run at a pace of 10 minutes per mile. He runs different distances on
different days. Each time he runs, he measures his blood sugar after
the run. (The preferred blood sugar level is between 80 and 120 on
this scale.) The data are in the file
[link](http://ritsokiguess.site/datafiles/runner.txt).  Our aim is
to predict blood sugar from distance.

To begin:

```{r}
library(tidyverse)
```



(a) Read in the data and display the data frame that you read
in.

Data values separated by a single space: 
 
```{r}
my_url <- "https://ritsokiguess.site/datafiles/runner.txt"
runner <- read_delim(my_url, " ")
runner
```
 
Looks like the data in the file.

(b) Make a scatterplot and add a smooth trend to it.
 
```{r}
ggplot(runner, aes(x = distance, y = blood_sugar)) + geom_point() + geom_smooth()
```

`geom_smooth` without anything else is good here because we don't yet know what kind of trend we have.

(c) Would you say that the relationship between blood sugar and
running distance is approximately linear, or not? It is therefore
reasonable to use a regression of blood sugar on distance? Explain briefly.
 
The smooth trend wiggles a little, but it seems that a downward-sloping line describes the trend well, and 
thus an ordinary linear regression will be good.

(d) Fit a suitable regression, and obtain the regression output.

The usual: `lm`, then `summary`:

```{r}
runner.1 <- lm(blood_sugar ~ distance, data = runner)
summary(runner.1)
```

R-squared is (very) high, and the slope is negative and significantly nonzero, so this is a real and 
downward trend.

Aside: if you were worried that a curve would be better, to accommodate the "wiggle" in the smooth trend, you could try adding a squared term:

```{r}
runner.2 <- lm(blood_sugar ~ distance + I(distance^2), data = runner)
summary(runner.2)
```
 
This is a complete waste of time! The squared term is nowhere near significant, and the increase in R-squared over `runner.1` is almost zero. So we can forget about this model from here on.
 
Aside 2: displaying the `summary` is the old way of looking at regression results, but perfectly good for a human looking at them. The `tidyverse`-style way to do it is to use `glance` and `tidy` from the `broom` package, which you will have to install first. `glance` gives you a one-row summary of the entire model, including things like R-squared, and `tidy` gives you the table with the intercept and slope and their P-values. 
 
```{r}
library(broom)
glance(runner.1) 
tidy(runner.1)
```
 
The value of these is that they are *dataframes*, so that anything you can do with dataframes, you can do with these, such as extracting numbers from them. This provides a quick way of getting hold of things like R-squared. 

(e) How would you *interpret* the slope? That is, what is
the slope, and what does that mean about blood sugar and running distance?
 
The slope is $-25.37$. This means that as distance goes up by 1 (the runner runs one mile further), his blood sugar falls by about 25 units on average.  

(f) Is there a (statistically) significant relationship between
running distance and blood sugar? How do you know? Do you find this
surprising, given what you have seen so far? Explain briefly.

The P-value for `distance` is $2.28 \times 10^{-8}$, extremely small, so there is definitely a significant relationship between running distance and blood sugar. The scatterplot suggested an unambiguous downward trend, so for me this is not surprising at all.

I skipped (g) and (h) (I haven't done these in lecture yet).

Let's do residual plots. I am not really expecting any problems here: we have a nice strong linear relationship with no obvious problems, but just to check:

```{r}
ggplot(runner.1, aes(x = .fitted, y = .resid)) + geom_point()
```

There is no pattern here. 

We said in tutorial that the human brain has a tendency to find patterns even when there are none (because that was how it evolved). If you stare at one of these too long, you will see something that looks like a pattern. Psychologists call this [apophenia](https://en.wikipedia.org/wiki/Apophenia). Related is "pareidolia", the tendency to see human faces in inanimate objects (like the "man in the moon"). The brain evolved to recognize human faces, so this is not really very surprising.

We should also check that the residuals are normal enough:

```{r}
ggplot(runner.1, aes(sample = .resid)) + stat_qq() + stat_qq_line()
```
 
 This is a little short-tailed (at the top), or it might appear left-skewed if you make a histogram. Short tails are not a problem; it's *long* tails that we need to worry about (residuals unusually far from zero). Both graphs, and therefore the regression as a whole, are entirely satisfactory.

